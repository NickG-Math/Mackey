\mainpage General Information
\tableofcontents
 \section intro Introduction
This is a C++ header only library devoted to numerically computing \f$RO(G)\f$ homology. You can find the GitHub repository <a href="https://github.com/NickG-Math/Mackey">here</a>.

For a quick demonstration in the case of \f$G=C_4\f$, use one of the available binaries  <a href="https://github.com/NickG-Math/Mackey/releases">here</a>.


\section req Requirements
 * C++17.
 * <a href=" http://eigen.tuxfamily.org/index.php?title=Main_Page">Eigen</a>, a header only library for matrix manipulation. 
 The code has been tested with Eigen 3.3.9.

Optionally:
 * For serialization we have integrated support for the <a href="https://uscilab.github.io/cereal">cereal</a> library.
 * To draw the multiplication graphs you can use <a href="https://www.graphviz.org">Graphviz</a>.
 
\section install Installation

* To install simply clone/download the <a href="https://github.com/NickG-Math/Mackey">repository</a> and include the folder called "source" in your path. 
You will also need to include Eigen and, if serialization is desired, cereal.

* See the page \ref use for a tutorial on using the library.

* As for compiler support, the latest version of the code is always tested with the latest stable versions of Clang, GCC (Linux) and MSVC (Windows). 
Remember to use the option ```-std=c++17```. For more information on compiler options, see the \ref perf page.

\section status Current Status

* The project is almost complete for \f$G\f$ a cyclic group of prime power order. 
The only input that's needed are the bottom level equivariant chains for the spheres corresponding to actual (as opposed to virtual) representations; we call these "standard chains". 
The standard chains can be easily computed from geometric equivariant decompositions by hand, and then fed into the program as explained in \ref how. We have implemented this for all groups \f$G=C_{2^n}\f$.

* Frobenius relations are yet to be implemented: The multiplicative structure is computed levelwise, but this could be done more effectively using the Frobenius relations. 

* For general cyclic groups a few aspects that involve transferring need reworking. For non-prime-power cyclic groups, the subgroup diagram is not a vertical tower but a somewhat more complicated diagram, 
so care has to be taken to account for all these extra transfers and restrictions. 
Ultimately this is the only part that needs changing.

* The bulletpoint above also applies to general finite abelian groups. We also need to specify the order of the elements of the group and how they relate to the subgroup diagram to form our equivariant bases.

* For non abelian groups, the real representation theory of the group would also be needed together with the standard chains. 

* Non constant coefficients are not supported (transferring becomes more complicated when non cyclic modules are involved in the free Mackey functors).

\section doc Documentation

This documentation is organized in pages as follows:
 
* The pages \ref index, \ref math, \ref use, \ref algo, \ref perf explain how the program works, starting from the math and moving to slightly more technical territory regarding the actual implementation.

* The pages <a href="namespaces.html">Namespaces</a>, <a href="annotated.html">Classes</a>  and <a href="files.html">Files</a> are automatically generated by doxygen from the source code (and comments in the source code). These offer a much more indepth look into all classes and functions of this project. Note that only public and protected members and named namespaces are documented.

* I recommend starting with the <a href="namespaces.html">related pages</a> before moving to the automatically generated ones. If you just want to use this library for computations, you only really have to go over the \ref how section.


\page math From Math to Code
\tableofcontents
\section Briefly

There are three fundamental ideas the code is based on:

* The homology of chain complexes of free modules can be algorithmically computed by turning the differentials into matrices and then diagonalizing them (Smith Normal Form). 

* Free Mackey functors (namely, free modules over a constant Mackey functor) are determined by their bottom level.
The higher levels are obtained by taking fixed points under the Weyl group action, and this can be done algorithmically on our matrices by writing them with respect to equivariant bases 
(an equivariant basis is an ordered basis in which elements in the same orbit are written consecutively).

* Box products of Mackey functors are tensor products on the bottom level. This is not true for the higher levels, however using the bulletpoint above, higher levels are obtained by transferring. 
This is how box products of chain complexes of free Mackey functors are computed.

These three ideas dictate our approach: 
We start with the standard chains (the chains for spheres \f$S^V\f$ where \f$V\f$ is an actual, as opposed to virtual, real \f$G\f$-rep) on the bottom level, and box them to get the bottom level chains
for any \f$S^V\f$ where \f$V\f$ is any virtual representation.
By transferring we get the higher level chains, from which the homology groups are computed level-wise.
The generators for these homology groups are defined on the chain level, where we can compute the transfer/restriction/Weyl group action on them. This means that we can compute the transfer/restriction/Weyl group action maps on homology, thus determining the Mackey functor structure of \f$H_*(S^V)\f$.

By converting all our differentials to matrices, using equivariant bases throughout, we can reduce our computations to pure linear algebra (over the integers, or other coefficients).


\section imd In more detail

Here's how the code works in more detail (for simplicity we specialize to the \f$G=C_4\f$ case, although everything works equally well with general prime powers):

\subsection add The additive structure

* The inputs are the bottom levels of the standard chains, namely the chains of the spheres \f$S^{n\sigma+m\lambda}\f$ for \f$n,m\ge 0\f$. It actually suffices to only use \f$S^{\sigma},S^{\lambda}\f$ as inputs and then obtain every other sphere
as iterated smash products of these, but this would result in taking arbitrarily many box products and incur a huge performance penalty. 
Instead, if we use the spheres  \f$S^{n\sigma+m\lambda}\f$ for \f$n,m\ge 0\f$ as inputs, we only have to take double box products at worst, and that's only for part of the multiplicative structure (see below).

* The data of a chain complex are the ranks of each \f$C_*\f$ and the differentials \f$d:C_*\to C_{*-1}\f$. 
The differentials are stored as matrices and the ranks are stored as integer arrays. Integer arrays and not integers are used in order to record the equivariant information: 
For example \f$\mathbb Z[C_4]\f$ is different from \f$\mathbb Z[C_2]\oplus \mathbb Z[C_2]\f$ even though they both have rank \f$4=2+2\f$ over \f$\mathbb Z\f$. 
With our conventions, \f$\mathbb Z[C_2]\oplus \mathbb Z[C_2]\f$ has rank \f$[2,2]\f$ while \f$\mathbb Z[C_4]\f$ has rank \f$4\f$.

* Starting with the bottom level chains, we transfer both ranks and differentials to get the higher level chains. 
While transferring ranks is straightforward, transferring differentials is quite a bit more complicated and requires to have already transferred the ranks of the domain and range of the differentials.

* Using the classical homology algorithm we compute the groups of the Mackey functor at every level. We also compute their generators (as elements in the chain complex).

* We transfer/restrict and compute the Weyl group action on these generators. This concludes the Mackey functor computation for the  \f$S^{n\sigma+m\lambda}\f$, \f$n,m\f$ having the same sign 
(if \f$n,m<0\f$ we take the dual chain complex, which has the effect of transposing all matrices for the differentials).

* To obtain the chains of any representation sphere, we box the standard chains. Boxing is more complicated compared to just taking tensor products, as we have to use equivariant bases throughout to transfer properly.
However the most convenient bases for tensoring (the lexicographical ones) are not equivariant, and in the end we have to change bases through permutation matrices.

* We then compute the homology of the boxed chains as above. 

\subsection mack "Universal" Additive Notation

While a Mackey functor is determined by the groups, transfers, restrictions and Weyl group actions, it is desirable to have a 
"universal" notation to concisely describe any Mackey functor. Here's the notation we use:

* First assume all levels are cyclic groups, and that in each transfer-restriction pair, one map is multiplication by 2 and the other map is multiplication by 1.
The notation \f$a_1...a_n \sharp b_1...b_m\f$ expresses a Mackey functor whose levels are \f$\mathbb Z/a_i\f$ if \f$a_i\neq 1\f$ and \f$\mathbb Z\f$ if \f$a_i=1\f$, with the bottom level corresponding to \f$a_1\f$ and the top to \f$a_n\f$. Furthermore, the transfers between levels \f$b_i\to b_{i+1}\f$ are multiplication by 1 (the rest of the transfers are multiplication by \f$2\f$ by assumption). 
The restrictions are computed by assumption, while the Weyl group actions are determined by the double coset formula.

* \f$a_1...a_n \sharp b_1...b_m + c_1...c_n\sharp d_1...d_l\f$ corresponds to the sum of Mackey functors of the above form. This generalizes to sums of more than 2 Mackey functors.

* For \f$C_4\f$, every Mackey functor can be written as above. For \f$C_8\f$ and \f$\mathbb Z\f$ coefficients there are three exceptional Mackey functors that can't be expressed in our "universal" notation.

\subsection iso Isomorphic Mackey Functors

Isomorphic Mackey functors can have different "universal" notations. 
To find if two different notations correspond to isomorphic Mackey functors (and are thus equivalent), it suffices to compute all different notations in each isomorphism class.

* Given a Mackey functor \f$M\f$ we compute its isomorphism class as follows: First, for each level \f$M(G/H)\f$ we find all its (group) automorphisms \f$Aut(M(G/H))\f$.
Choosing one automorphism for each \f$H\f$ gives a Mackey functor automorphism of \f$M\f$ (as long as the level-wise choices commute with restrictions/transfers/Weyl group actions). 
In the end we get \f$Aut(M)\f$ and applying the automorphisms on \f$M\f$ returns the isomorphism class.

* For finitely generated (abelian) groups with only one \f$\mathbb Z\f$ factor, there are only finitely many automorphisms and
we can easily classify them all.

* If there is more than one \f$\mathbb Z\f$ factor, there are infinitely many automorphisms, 
so the user must provide those that the program should use for the identification. 


\subsection mult The multiplicative structure

Once we have the additive structure (the universal notation isn't needed for this), we can compute the product of two additive generators \f$a,b\f$ through the following process. 

* First we restrict the generators \f$a,b\f$ to the bottom level to get \f$Res(a),Res(b)\f$ as elements of two chain complexes.

* We then compute \f$Res(a)Res(b)\f$ as an element of the box product of the two chain complexes on the bottom level.

* \f$Res(a)Res(b)\f$ is the restriction of a unique element, \f$ab\f$ (since our chains are free Mackey functors). By inverting the restriction we can get \f$ab\f$ as an element of the box product.

* We finally write \f$ab\f$ in terms of the generators of the homology of the box product.

Once we know how to multiply any two additive generators, we have in effect determined the multiplicative structure (see \ref caveat for a catch).

\subsection factor Factorization

Even if we can multiply any two generators, that doesn't mean we can automatically write any element as a product of our preferred generators. 
For example, it's easy to see that the generator of \f$H_{-2}S^{-2\sigma}\f$ is \f$2/u_{2\sigma}\f$ (multiply with \f$u_{2\sigma}\f$ and get result \f$1\f$).
On the other hand, coming up with the expression \f$2/u_{2\sigma}\f$ of the generator is a lot more complicated. 
The factorization process performs this automatically:

* First we form a multiplication table, where all generators (in a range) are multiplied with the "basic irreducibles". These basic irreducibles can be the Euler and orientation classes.

* We then get a directed colored graph by drawing \f$a\to ab\f$ for \f$b\f$ a basic irreducible; we color these edges red.
 If multiplication by \f$b\f$ is an isomorphism i.e. \f$a=(ab)/b\f$ then we also draw \f$ab\to a\f$; we color such edges blue.

* Since the product \f$ab\f$ may not be a generator, but rather a multiple of it, we need to allow nonzero multiples of generators as distinct nodes.

* To obtain a factorization, we simply need to connect 1 with any node in the graph. 
For the most efficient factorizations, we want to minimize the number of times we alternate between blue and red edges in each path (eg we prefer \f$b^2\f$ to \f$a(b/a)b\f$). 
This is done by a modified Dikjstra algorithm.

* For the generators not connected to 1 (eg \f$s\f$) we need to perform the same process using different sources for our graph (eg using \f$s\f$ as the source for all paths).

\subsection Mass Massey Products

The chains-based approach we use means that Massey products can be computed from definition. The only extra thing we need is the following:

* Given an element \f$x\f$ that vanishes in homology we can find a \f$y\f$ that bounds it: \f$dy=x\f$. This is part of our homology algorithm.

So Massey products work like this:

* Suppose we have \f$ab=bc=0\f$ in homology. We lift \f$a,b,c\f$ to chains \f$C,D,E\f$ and explicitly compute \f$ab, bc\f$ in \f$C\otimes D\f$ and \f$D\otimes E\f$ respectively, as in \ref mult.

* After that we find \f$ds=ab, dt=bc\f$ and form \f$sc\f$ and \f$at\f$ in the box products \f$(C\otimes D) \otimes E\f$ and \f$C\otimes (D\otimes E)\f$ respectively.

* These box products are isomorphic up to a permutation that we can explicitly compute. Thus we can write \f$sc\f$ and \f$at\f$ as elements of the same chain complex in the same basis.

* Finally we form \f$sc+(-1)^{|a|+|b|+1}at\f$ and compute its image in homology.

\section caveat A caveat
\subsection cyclic Cyclic Generators

* The way we prove that a transfer map is (say) multiplication by \f$2\f$, is by computing the generators at the domain and target, computing the transfer of the domain generator and comparing with the target. 
Of course, there are usually multiple choices of generators, but up to isomorphism we get the same Mackey functor. 

* There is a catch however that appears when computing the multiplicative structure: If we prove that \f$ab\f$ and \f$cd\f$ are both generators of the same cyclic group, then we can't conclude that they are equal. 
Eg if the group is \f$\mathbb Z/4\f$ or \f$\mathbb Z\f$ then they may differ by a sign. 
Still, since we are interested in generating the \f$RO(G)\f$ homology, as opposed to finding exact relations, we don't have to distinguish between cyclic generators so we don't need to worry about this detail.

* If we are interested in exact relations, then are ways to resolve the ambiguity as we explain in the following subsection.


\subsection noncycl Non cyclic generators

* There is a situtation where the caveat above cannot be worked-around and that's when we have non cyclic groups. A typical example: 
If we have \f$\mathbb Z\oplus \mathbb Z/2\f$ with generators \f$x,y\f$ respectively then we can't distinguish \f$x\f$ from \f$x+y\f$ as there is an automorphism of \f$\mathbb Z\oplus \mathbb Z/2\f$ exchanging them. 
In that case the difference between \f$ab\f$ and \f$cd\f$ generating the same group can be greater than just an integer coprime to the group's order (or a sign).

* For another example, when computing the \f$RO(C_4)\f$ homology in \f$\mathbb F_2\f$ coefficients the group \f$\mathbb F_2\oplus \mathbb F_2\f$ tends to appear frequently; 
unfortunately its three generators cannot be distingusihed.

* One way out of this is to break down our box products further until they can be directly compared. Eg we can compare the chains for \f$S^{2\sigma+\lambda}\wedge S^{-\lambda}\f$ with those for
\f$S^{\sigma+\lambda}\wedge S^{\sigma -\lambda}\f$ by using the chains for \f$S^{\sigma}\wedge S^{\sigma}\wedge S^{\lambda}\wedge S^{-\lambda}\f$ as an intermediate. 
This is difficult to program generally and comes at a very high performance cost as we need more iterated box products.

* Another way is to use the fact that these noncyclic homology groups result from extensions of Mackey functors, not just group extensions. 
So for example in \f$\mathbb Z\oplus \mathbb Z/2\f$ we can distinguish \f$x\f$ from \f$x+y\f$ using that \f$x\f$ is a transfer. 
This doesn't always work: We can have a \f$\mathbb F_2\oplus \mathbb F_2\f$ generated by \f$x,y\f$  with \f$x\f$ having restriction \f$0\f$ while \f$y\f$ having restriction \f$1\f$ and no generator being a transfer;
in this case we cannot distinguish between \f$y\f$ and \f$x+y\f$.

* There is one final trick we can use to resolve this ambiguity as it appears the Factorization algorithm: Assume we have \f$ab\f$ in \f$\mathbb F_2\{x,y\}\f$ and we know \f$ab=x\f$ or \f$ab=x+y\f$.
For each element \f$z\f$ we can compute the products \f$xz\f$ and \f$(x+y)z\f$. 
If for some \f$z\f$ these products are different and can be distinguished, say \f$c,d\f$, then we can form \f$abz\f$ internally (triple box product) and compare the answer to \f$c\f$ and \f$d\f$; 
if \f$abz=c\f$ then \f$ab=x\f$.

In practice, for \f$\mathbb Z\f$ coefficients and \f$G=C_4\f$ we can choose to ignore the products we can't immediately identify and make no determination as to the equality of \f$ab\f$ and \f$cd\f$ if they live in non cyclic groups. 
This gives us less data to work with, but it turns out to be sufficient in writing the factorization of any element. 

That doesn't work for \f$\mathbb F_2\f$ coefficients and \f$G=C_4\f$, or \f$\mathbb Z\f$ coefficients and \f$G=C_8\f$, as there are simply too many instances of noncyclic groups. 
Instead we need to use all the bulletpoints above to identify our generators and factorize every element.

If we are only interested in the connectivity of the multiplication graph (whether or not everything being generated by Euler+orientation classes) then we don't need to make all identifications:
If \f$ab\f$ is \f$x\f$ or \f$x+y\f$ and \f$x,y\f$ are connected to the source of the graph and multiplication by \f$b\f$ is an injection on \f$a\f$, then it doesn't matter if the
answer is \f$x\f$ or \f$x+y\f$: in both cases, \f$a\f$ is also connected to the source. 

\page use How to Use
\tableofcontents
\section how Step 0: Setting the Group Parameters

For every group there are certain parameters that need to be set for the library to work. 
We have included an example for \f$G=C_4\f$ on how to set them in the file  ```C4_Implementation.h``` available in the <a href="https://github.com/NickG-Math/Mackey/tree/master/demo">demo</a> folder. 
We also have a more general example for all \f$G=C_{2^n}\f$ implemented in ```C2n_Implementation.h```.

These parameters all live in the \ref GroupSpecific "GroupSpecific" namespace and we will go over them in more detail below.

\subsection var Global variables

The global variables that need to be set are:

* \ref GroupSpecific::Variables::prime "prime" : the \f$p\f$ in \f$G=C_{p^n}\f$.
* \ref GroupSpecific::Variables::power "power" : the \f$n\f$ in \f$G=C_{p^n}\f$.
* \ref GroupSpecific::Variables::reps "reps" : the number of nontrivial irreducible real representations of \f$G\f$ for our spheres.
* \ref GroupSpecific::Variables::sphere_dimensions "sphere_dimensions" : the array consisting of the dimensions of those representations (so we must fix an order for them beforehand).

\subsection fun The standard chains

* There is one function that needs to be manually defined, the \ref GroupSpecific::Function::PositiveChains "PositiveChains" computing the chains for actual (as opposed to virtual) representation spheres. 
The construction of these Chains is made as painless as possible, using the \ref Mackey::altmatrix "altmatrix" function

* \ref Mackey::altmatrix "altmatrix" returns alternating matrices of the desired size and the desired "pattern". This pattern is repeated cyclically in the columns of the matrix. 
An example: The matrix of size 4x4 with pattern \f$a,b\f$ is <br>
\f$\begin{matrix} a&b&a&b\\ b&a&b&a\\ a&b&a&b \\  b&a&b&a \end{matrix}\f$ <br> 
If we use the pattern \f$a,b,c,d\f$ instead we get <br>
\f$\begin{matrix} a&b&c&d\\ b&c&d&a\\ c&d&a&b \\  d&a&b&c \end{matrix}\f$ <br> 

* The matrices appearing in the Standard Chains all look like this due to equivariance.

We have automated this process for general \f$G=C_{2^n}\f$ in ```C2n_Implementation.h``` using the recursion established in HHR17 pg 392. All that needs to be changed is the power variable.

\section next Step 1: Calling the library

Once Step 0 is complete, you can include ```Additive.h``` to access the methods relating to the additive structure and ```Factorization.h``` to access the factorization methods. 
The multiplicative structure and Massey products are found in ```Compute.h``` but that's already included in the other two headers.

For a demonstration you can use the cpp files included in the <a href="https://github.com/NickG-Math/Mackey/tree/master/demo">demo</a> folder together with the provided Implementation header file (Step 0).

The namespace for all methods is ```Mackey```.

\subsection coeff Coefficients and templates

There are two template arguments that always need to be specified, and their typenames are always ```rank_t,diff_t```. These are the coefficients used for the rank arrays and differential matrices respectively. 

* ```rank_t``` can be set to ```Eigen::Matrix<char,1,-1>``` for groups of prime power order \f$<127\f$ and we can replace ```char``` by better precision integers for higher prime power orders.

* ```diff_t``` depends on the desired coefficients: eg we can set it to ```Eigen::Matrix<char,-1,-1>``` for integer coefficients and groups of small power order, or ```Eigen<Z<N>,-1,-1>``` for \f$\mathbb Z/n\mathbb Z\f$ coefficients. The user can also define a class of coefficients and use that instead as well. An example of how this is done is 
contained in the file ```Z_n.h``` where we define \f$\mathbb Z/n\mathbb Z\f$ coefficients. Note that for the Smith normal form to work properly, \f$n\f$ should be a prime.

Important note: ```diff_t``` can also be set to a sparse matrix format like ```Eigen::SparseMatrix<char>``` or ```Eigen::SparseMatrix<char,0,long>``` (using ```long``` storage type for matrix dimensions). 
See the  \ref perf page for more information.

\subsection step1add The additive structure

The file ```Additive.h``` exposes the class \ref Mackey::AdditiveStructure "AdditiveStructure" that computes the homology of all spheres in a given range as Mackey functors. Example: The code

<CODE> AdditiveStructure<rank_t,diff_t> A({-3,-4},{5,6}); </CODE>

computes the homology of all spheres from \f$S^{-3\sigma-4\lambda}\f$ to \f$S^{5\sigma+6\lambda}\f$. To identify the Mackey functors in the "universal" notation
use

<CODE> A.identify(); </CODE>

After that,

<CODE> A.print_answer(stream); </CODE>

prints the answer in a user provided ```stream``` (eg you may pass ```std::cout``` to ```print_answer```). The answer is of the form

<CODE> The 2 homology of the 4,6 sphere is 002 </CODE>

 as long as the Mackey Functor has been identified. You can survey the identified Mackeys by
 
 <CODE>
A.print_unique(stream);
 </CODE>
 
 For \f$C_8\f$ there are three Mackey functors not covered by our "universal notation" and are thus named "unknown 0,...".
 To survey their Mackey functor structure use
 
  <CODE>
A.print_unknown(stream);
 </CODE>


 
\subsection step1mult The multiplicative structure

The file ```Compute.h``` exposes the method \ref Mackey::ROGreen "ROGreen" that multiplies two generators in the Green functor \f$H_{\star}(S)\f$. Example: The code

<CODE> auto linear_combination= Mackey::ROGreen<rank_t,diff_t>(2,{0,2,-2},{1,3,-4}); </CODE>

performs the operation

\f$ H_0^{C_4}(S^{2\sigma-2\lambda}) \otimes H_1^{C_4}(S^{3\sigma-4\lambda}) \to H_1^{C_4}(S^{5\sigma-6\lambda})  \f$, \f$ a\otimes b\mapsto ab\f$

where \f$a,b\f$ are generators. The answer is written as a linear combination of the generators in the latter homology group. 
The first argument of \ref Mackey::ROGreen "ROGreen" indicates the level the generators live in (level 0=bottom, level 1= one higher etc.) so for \f$C_4\f$, level=2 is the top level. 
The second and third entries are the degrees of the two generators.

If the homology in these degrees is not cyclic, then the generators are not determined by their degree and need to be selected. 
In that case we can provide an optional final 2 ```int``` arguments in ```Mackey::ROGreen``` that perform the selection: eg \f$1,2\f$ selects the second and third generators of the noncyclic groups respectively.
 The default selection is \f$0,0\f$.

The result of the computation ```linear_combination``` is an Eigen row vector (```rank_t```) that can be intrepreted as follows: if the result is \f$[t_1,...,t_n]\f$ then 
\f$ ab=\sum_it_ig_i\f$
where \f$g_i\f$ are the generators of the homology group the product lives in.

For convenience we normalize the basis to omit any signs and identify generators of the same cyclic groups (see \ref caveat) but it's also possible to get the nonnormalized version (\ref Mackey::Green).


\subsection step1fact Factorization

The file ```Factorization.h``` exposes the class \ref Mackey::Factorization "Factorization" whose constructor creates the multiplication graph and the method 
\ref Mackey::Factorization::compute_with_sources "compute_with_sources" that factorizes all generators using the given sources. First construct the multiplication graph via:

<CODE>auto F= Factorization<rank_t, diff_t>(2,{ -5,-5 }, { 5,5 }, { {0,1,0},{2,2,0},{0,0,1},{2,0,1} }, { "asigma", "u2sigma", "alambda", "ulambda" });</CODE>

This will work on level \f$2\f$ (top level for \f$C_4\f$), in the range from \f$S^{-5\sigma-5\lambda}\f$ to \f$S^{5\sigma+5\lambda}\f$,
by multiplying all generators of \f$H_{\star}S\f$ with the basic irreducibles \f$ a_{\sigma}, u_{2\sigma}, a_{\lambda}, u_{\lambda}\f$ of degrees \f$[0,1,0],[2,2,0],[0,0,1],[2,0,1]\f$ respectively.

Then 

<CODE>F.compute_with_sources({{0,0,0}}, {"1"});</CODE>

computes the factorizations by connecting every node in the multiplication graph to \f$1\f$ (if possible). To print the generator at degree \f$[3,1,0]\f$ use:

<CODE>std::cout<< F.getname({3,1,0}) </CODE>

To print the names of all generators use:

<CODE>std::cout<< F.get_generators() </CODE>

To print the multiplication graph to an ```std::ofstream file``` use:

<CODE>file << F.getgraph() </CODE>

or

<CODE>file << (F.getgraph() << F.get_generators()) </CODE>

if you want the generator names as labels for the nodes.

A generator name being \f$?\f$ means that the generator could not be obtained by multiplying/dividing the basic irreducibles with ```1```. This means that additional sources may need to be added, such as through:

<CODE>F.compute_with_sources({{0,0,0},{-3,0,-2}}, {"1","s"});</CODE>

where now both \f$1\f$ and \f$s\f$ are used as sources.

It possible that there are enough sources yet you still get \f$?\f$; that means the basic identification was not enough to compute all products. You can then use

<CODE>F.pass_disconnected();</CODE>

to try redoing the identification now using triple box products. This will be very computationally expensive.

Finally, if only the connectivity of the Multiplication Graph is desired, as opposed to precise factorizations of the generators, you can instead and use

<CODE>auto M= MultiplicationGraphConnectivity<rank_t, diff_t>({ -5,-5 }, { 5,5 }, { {0,1,0},{2,2,0},{0,0,1},{2,0,1} });</CODE>

and then

<CODE>M.compute_with_sources({[0,0,0]});</CODE>

The vector <CODE>M.trully_disconnected</CODE> contains the indices of the generators that may not be connected to any sources.

\subsection step1Mass Massey products


The file ```Compute.h``` finally exposes the method \ref Mackey::ROMassey "ROMassey" for (triple) Massey products in the Green functor \f$H_{\star}(S)\f$. Example: The code


<CODE>auto Mass= Mackey::ROMassey<rank_t,diff_t>(2,{0,1,0},{-3,-3,0},{2,2,0},1);</CODE>

computes the Massey product \f$\langle a_{\sigma},w_3,u_{2\sigma}\rangle \f$ and its indeterminacy (if indeterminacy is not needed, use \f$0\f$ as the last variable). 
As with the multiplicative structure, the Massey product is expressed in terms of a linear combination of the basis in the homology of the box product,
while the indeterminacy is expressed via two two groups (left and right indeterminacy). If both are \f$0\f$ then we have the member variable ```noIndeterminacy=1```. 

We can also provide three optional ```int``` arguments at the end for selections, see \ref step1mult for what that does.

Finally, ```Mass``` is of type ```Mackey::Massey``` so read the documentation of that class to see how to extract the relevant data.

For more details see the code in TestMassey.cpp of the <a href="https://github.com/NickG-Math/Mackey/tree/master/demo">demo</a> folder


\subsection step1Cer Serialization

The results of the computationally expensive computations can all be serialized to binary, xml or json files using the <a href="https://uscilab.github.io/cereal">cereal</a> library. We have provided a general 
interface to do that using the \ref Mackey::saver "saver" and \ref Mackey::loader "loader" methods. For example, to serialize ```AdditiveStructure<rank_t,diff_t> A;``` to a binary use

<CODE>saver(A, "filename.bin", "binary");</CODE>

To load use

<CODE>loader(A, "filename.bin", "binary");</CODE>

If ```xml``` serialization is desired use "file.xml" and "xml" instead and similarly for json archives.

\page algo Select Implementation Details
\tableofcontents

\section smith Smith Normal Form

There are multiple ways to compute the Smith Normal Form of a matrix, but since we are mostly interested in the coefficient matrices, we employ the
row/column elimination algorithm. To use the algorithm we need to be able to choose a pivot for our matrix each time we want to clear a row and column.
We have the freedom to choose it and there are (at least) three ways to do it:

* Use the first nonzero element as pivot, and if a smaller nonzero element (in absolute value) appears during the elimination then switch to that.
* Use the minimum (in absolute value) nonzero element as pivot. If there are multiple choices, pick the first one as we iterate through the matrix.
* As above, but instead of picking the first minimum, choose it so that it minimizes a certain norm function.

This norm function, called a Markowitz metric, can be for example
\f$N(i,j)=|\{a_{is}\neq 0: s\}| + |\{a_{sj}\neq 0:s\}|\f$

One reason we are considering multiple pivoting choices is coefficient explosion: Even if the entries of the matrix are small (\f$\pm 1\f$),
the entries of the Smith Normal Form (and especially those of the coefficient matrices) can easily overflow if we make the wrong choice of pivot.
You can read more about this problem in  <a href="https://arxiv.org/abs/math/9406205">Recognizing badly presented Z modules</a>.

Of the three choices above, the first is most likely to result to overflow, but is usually the fastest when it doesn't.
The second is a great option for smaller matrices (<1000 rows and columns) while the third excells with very big matrices.

But there is another reason to use the third option, and that's sparse matrices.

When our matrices get large (7000 rows and columns) they are also very sparse (99.9% entries being 0) so we can make huge
savings on memory (and potentially computational time) by using a sparse matrix format that only records the nonzero values.

The usage of sparse matrices necessitates great care lest we incur severe performance costs :
For example, insertions of nonzero elements and random access do not have constant complexity.

As far as the Smith normal form is concerned, to have good performance with sparse matrices we need to minimize fill-in, which
is the creation of nonzero elements from adding a row/column to another one. The Markowitz metric described above is used
to very roughtly estimate the fill-in that we would get if the given element was used as pivot. There are many other
choices as explained  <a href="https://arxiv.org/abs/math/9406205">here</a>.

Thus in total we have 4 Smith implementations:

* ```Mackey::SmithFP``` using the first nonzero element as pivot. Called in the dense finite coefficient case.
* ```Mackey::SmithMP``` using the minimum (in absolute value) nonzero elemenent as pivot (first instance). Called for dense matrices with at most 1000 rows and columns.
* ```Mackey::SmithSP``` using the instance of the minimum that also minimizes a norm function. Called for dense matrices with above 1000 rows and columns.
* ```Mackey::SmithSparse``` which is the same as ```Mackey::SmithSP``` but using sparse matrices. Called for sparse matrices.



\section cob Change of Basis

If we have bases for modules \f$A,B\f$ then \f$A\otimes B\f$ can be canonically given two lexicographical bases, that we call left and right convenient bases. 
But if \f$A,B\f$ are the bottom levels of free Mackey functors then they have equivariant bases and the tensor product also gets an equivariant basis, called the canonical one. 
The left and right convenient bases are used to write the left and right differentials \f$L,R\f$ (see \ref box) in a simple manner (hence their designation as convenient). The canonical bases are needed to transfer however, so we compute the change of basis matrices from the convenient to the canonical bases. 

\section box Box product

Computing the tensor product of Chain complexes breaks down to computing the left and right differentials \f$L(x\otimes y)=dx\otimes y\f$ and \f$R(x\otimes y)=(-1)^{|x|}x\otimes dy\f$ respectively. If we use the convenient bases explained in the previous section, these are just block diagonal matrices with the blocks being the differentials \f$d,d'\f$ from the original chains. To get \f$L,R\f$ w.r.t. the canonical bases, we need to apply the change of basis matrices. Once we do that the total differential of the tensor product is just \f$L+R\f$. To be more accurate, \f$L\f$ is not a single differential, but rather a sequence of them, one for each summand of the Box product; \f$(C\otimes D)_n\to (C\otimes D)_{n-1}\f$ is a map \f$C_n\otimes D_0\oplus\cdots \oplus C_0\otimes D_n\to C_0\otimes D_{n-1}\oplus\cdots\oplus C_{n-1}\otimes D_0\f$. Each summand of this map is computed separately into an \f$L\f$ and an \f$R\f$, and then these are mixed together to form the total differential. The mixing specifies that we start with a block \f$ L_0\f$, then place \f$ R_0\f$ directly below it, then \f$L_1\f$ adjecent to the right of \f$ R_0\f$ etc.

\section graph Graphs

* For weighted graphs we want the shortest path from a given source to all other points. That's done via a straightforward implementation of Dikjstra's algorithm using std::priority_queue.

* For graphs of two colors, we are interested in the paths from the source to all points with the minimum numer of alternating colors (an alternation of colors means switching from division to multiplication and vice-versa). 
This problem can be easily reduced to finding the shortest path for weighted graphs, by using a sort of "dual" graph where now the nodes are colored and the edges are monochrome. Edges between same colored nodes have weight 1, while for different colored nodes we get weight 2.
To get the new graph simply duplicate the nodes of the original, color the originals by red and the new ones by blue, and quadruple the edges (so we are using all combinations of colored nodes) and set the weights as explained.
After that, find the red and blue paths starting from a red/blue source and ending at each point, compare them in length and choose the shortest one.


\page perf Performance
\tableofcontents

First, two heuristic observations:

* The Linux binaries runs measurably faster than the Windows one.
* Out of the three compilers on Linux tested (GCC, Clang, ICC), Clang seems to produce faster code. 

\section compoptions Compiler Options


* I recommend the following compiler options (GCC, Clang): <CODE>-O3 -funroll-loops -march=native </CODE>
* For safety you can use -fsanitize=signed-integer-overflow that checks for integer overflow at minimum performance cost. For extra safety, -fsanitize=integer checks all kinds of unwanted integer behavior (eg unsigned overflow) at a slightly higher cost. More generally -fsanitize=undefined can be used to check for all undefined behavior (and more) at a much greater performance hit (about 10x slower).
* See this <a href=" http://eigen.tuxfamily.org/index.php?title=Main_Page#Compiler_support">page</a> for compiler options regarding Eigen.
* If OpenMP support is desired use ```-fopenmp```.

\section thread Multithreading

* The main algorithms of the program are single-threaded, with the idea being that they will be performed in loops, computing the answer in a range (which is required for the identification algorithms to then work). Multithreading these loop iterations with openMP is turned on by default in the ```AdditiveStructure``` and ```Factorization``` code, using the maximum amount of threads available. But note that other parts of the library (using ```std::map```) are not thread-safe and need to be locked; thankfully these have almost no bearing on performance. 

* There is one caveat: While the loop iterations are independent, they are not all equally computationally intensive. A sphere like \f$S^{2\sigma+\lambda}\f$ is cheaper to compute compared to \f$S^{6\sigma+8\lambda}\f$ which is in turn much cheaper compared to \f$S^{6\sigma-8\lambda}\f$ as the latter one involves a box product. In the multiplicative structure we may have to take double box products, and these are even more expensive in run-time as they involve arbitrarily large permutation matrices.

* So it's important to equally divide the work among the threads. Currently this has to be done manually on the user's end.

\section densevssparse Dense vs Sparse

* Dense matrices are usually faster than sparse matrices, as long as they don't get too large. For the few instances where matrix multiplication is used, linking against the 
Intel MKL can also drastically improve performance with floating points (see below). 

* When matrices do get large, sparse matrices not only offer better performance, but exremely significant savings in memory (30x and above). When triple box products are used in combination with dense matrices and multithreading, memory usage can go up to 60GB, hitting the swap file and slowing the program to a crawl. In that case we can see up to 20x speedup when using sparse matrices. The Intel MKL is not any faster than Eigen for sparse matrix multiplication.

\section intvsfloat Integers vs Floats

Er use integers (or indeed ```char``` and ```short```) for the majority of the computations; that's usually the fastest method and makes the most sense (as all numbers appearing are actually integers).
There is one important exception: Dense matrix multiplication (and to a lesser extent matrix determinant). Eigen is much slower with integer matrix multiplication compared to floating points, and the Intel MKL does not even support integer matrix multiplication.
So when we need to multiply matrices we cast them to floats. This is only needed for the Homology algorithm, which is at the very end of the pipeline (together with the Smith Normal Form) so we can benefit from smaller integer types before casting.


\section boxproducts Box Products 

Box products involve some very large matrices, and the more iterated box products we use the higher that complexity. 

* For the additive structure we only need to take one box product:

\f$C_*(S^V)=C_*(S^{V_{pos}})\otimes C_*(S^{-V_{neg}})=C_*(S^{V_{pos}})\otimes C^{-*}(S^{V_{neg}})\f$

where \f$V=V_{pos}-V_{neg}\f$

* For the multiplicative structure we need to take an extra box product, so up to three total when computing \f$ab\f$ for \f$a,b\f$ in the mixed homology. 

* For factorization we would also need three box products. But by design, we are only multiplying with certain basic irreducibles (Euler and orientation classes) and hope everything else is obtained like this. By selecting them to be in the pure co/homology (which the Euler and orientation classes always are) we can reduce this to two box products total. If extra identification needed then we do take triple box products, incurring a massive performance and memory cost.

* For Massey products we need an extra two box products, so up to five total then computing \f$\langle a,b,c\rangle \f$ for \f$a,b,c\f$ in the mixed homology.
