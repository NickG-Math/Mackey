\hypertarget{algo_smith}{}\section{Smith Normal Form}\label{algo_smith}
For the Smith Normal Form we use a variant of the classical row-\/column elimination algorithm. Interestingly, for our matrices, an entry divides or is divided by any other. We optimize for this by not finding the minimum elements of the matrix, and instead working with the first nonzero element in each row and column. This is much faster for our matrices, but slower and much more dangerous for random matrices\+: the Smith normal form coefficient matrices $P,Q$ can easily overflow in that case (while the usual row-\/column elimination algorithm can give accurate results).\hypertarget{algo_cob}{}\section{Change of Basis}\label{algo_cob}
If we have bases for modules $A,B$ then $A\otimes B$ can be canonically given two lexicographical bases, that we call left and right convenient bases. But if $A,B$ are the bottom levels of free \hyperlink{namespaceMackey}{Mackey} functors then they have equivariant bases and the tensor product also gets an equivariant basis, called the canonical one. The left and right convenient bases are used to write the left and right differentials in a simple manner (hence their designation as convenient). The canonical bases are used to transfer. \hypertarget{algo_box}{}\section{Box product}\label{algo_box}
Computing the tensor product of Chain complexes breaks down to computing the left and right differentials $L(x\otimes y)=dx\otimes y$ and $R(x\otimes y)=(-1)^{|x|}x\otimes dy$ respectively. If we use the convenient bases explained in the previous section, these are just block diagonal matrices with the blocks being the differential from the original chains $d$. To get $L,R$ w.\+r.\+t. the canonical bases, we need to apply the change of basis matrices explained above. Once we do that the total differential of the tensor product is just $L+R$. To be more accurate, $L$ is not a single differential, but rather a sequence of them, one for each summand of the Box product. That is, $(C\otimes D)_n\to (C\otimes D)_{n-1}$ is a map $C_n\otimes D_0\oplus\cdots \oplus C_0\otimes D_n\to C_0\otimes D_{n-1}\oplus\cdots\oplus C_{n-1}\otimes D_0$. Each summand of this map is computed separately into an $L$ and an $R$, and then these are mixed together to form the total differential. The mixing specifies that we start with a block $ L_0$, then place $ R_0$ directly below it, then $L_1$ adjecent to the right of $ R_0$ etc.\hypertarget{algo_graph}{}\section{Graphs}\label{algo_graph}

\begin{DoxyItemize}
\item For weighted graphs we want the shortest path from a given source to all other points. I use a straightforward implementation of Dikjstra\textquotesingle{}s algorithm using std\+::priority\+\_\+queue.
\item For graphs of two colors, we are interested in the paths from the source to all points with the minimum alternations of colors (an alternation of colors means switching from division to multiplication and vice-\/versa). This problem can be easily reduced to the previous bullet, by using a sort of \char`\"{}dual\char`\"{} graph where now the nodes are colored and edges between same colored nodes have weight 0, while for different colored nodes we get weight 1. To get the new graph simply duplicate the nodes of the original, color the originals by red and the new ones by blue, and quadruple the edges (so we using all combinations of colored nodes). After that we can find the red and blue paths starting and ending from a red/blue source and compare them in length, choosing the shortest one. 
\end{DoxyItemize}