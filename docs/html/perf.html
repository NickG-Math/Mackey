<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Mackey: Performance</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/NativeMML"],
});
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="logo.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Mackey
   &#160;<span id="projectnumber">1.0</span>
   </div>
   <div id="projectbrief">A C++ library for computing the RO(G) homology of a point</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('perf.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Performance </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="compoptions"></a>
Compiler Options</h1>
<ul>
<li>Clang seems to produce marginally faster code.</li>
<li>The Linux binary runs measurably faster than the Windows one.</li>
<li>I recommend the following compiler options (GCC, Clang): <code>-Ofast &ndash;funroll-loops -march=native </code></li>
<li>With the Intel and Microsoft compilers Eigen recommends <code>-inline-forceinline</code> option.</li>
<li>Note: <code>-Ofast</code> doesn't actually reduce the accuracy of our results, since we only use integers even if the data-type is sometimes a floating point (see <a class="el" href="perf.html#intvsfloat">Integers vs Floats</a> for an explanation as to why we do that). </li>
</ul>
<h1><a class="anchor" id="thread"></a>
Multithreading</h1>
<ul>
<li>While the <a href="https://github.com/NickG-Math/Mackey/tree/master/bin">binaries</a> are all single-threaded, the most (by far) computationally intensive calculations can be multithreaded extemelly easily and efficiently. This is as simple as adding a <code>#pragma omp parallel for</code> before certain loops that compute the additive/multiplicative structure in a range. There is no need to lock anything.</li>
<li>There is one caveat: While the loop iterations are independent, they are not all equally intensive. A sphere like \(S^{2\sigma+\lambda}\) is cheaper to compute compared to \(S^{6\sigma+8\lambda}\) which is in turn much cheaper compared to \(S^{6\sigma-8\lambda}\) as the latter one involves a box product. In the multiplicative structure we may have to take double box products, and these are by comparison much more expensive in run-time as they involve arbitrarily large permutation matrices.</li>
<li>So it's important to equally divide the work amongst the thread. At this point, this has to be done manually.</li>
</ul>
<h1><a class="anchor" id="intvsfloat"></a>
Integers vs Floats</h1>
<p>I use integers (or indeed <code>char</code> and <code>short</code>) for the majority of the computations; that's usually the fastest method and makes the most sense (as all numbers appearing are actually integers). There is one important exception: Matrix multiplication. Eigen is much slower with integer matrix multiplication compared to floating points, and the Intel MKL does not even support integer matrix multiplication. So when we need to multiply matrices we cast them to floats. This is only needed for the Homology algorithm, which is at the very end of the pipeline (together with the Smith Normal Form) so we can benefit from smaller integer types before casting.</p>
<h1><a class="anchor" id="memo"></a>
Memoizing ChangeBasis</h1>
<p>To form the Box product of Chains we need the change of basis matrices. These matrices only depend on the ranks of the given Chains, call them rank1 and rank2. The ranks that actually come up in our computations always look like [?,order,...,order,?] where order is the order of the group and ? \(\le\) order. This means that we very effectively memoize this function for better performance.</p>
<h1><a class="anchor" id="bottle"></a>
Bottlenecks</h1>
<ul>
<li>The biggest performance bottleneck is found in the multiplicative structure. That's when we apply some large change of basis matrices through Eigen's permutation matrix product. This is a memory bottleneck.</li>
<li>The second biggest bottleneck lies in the transfering very large differentials. To transfer we need to delete certain rows of the matrix, and this is done by copying the remaining rows into a new matrix. This is a memory bottleneck.</li>
<li>A more minor bottleneck is the Smith normal form computation. The problem is that it involves going through our matrix both by rows and by columns, which is not ideal for cache locality. The SNF is both memory and core bound. </li>
</ul>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
