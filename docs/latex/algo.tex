\hypertarget{algo_smith}{}\section{Smith Normal Form}\label{algo_smith}
The Smith Normal Form is difficult to compute for integer matrices as its entries (and especially the entries of the coefficient matrices) can be much larger than those of the original matrix, leading to potential overflow. We have implemented two versions of the usual row/column elimination


\begin{DoxyItemize}
\item The safe version checks for the minimum (amongst the nonzero entries and in absolute value) in each iteration and uses it as a pivot to clear rows and columns.
\item The fast version forgoes the inefficient min computation and instead uses the first nonzero element it finds as pivot.
\end{DoxyItemize}

Using a S\+F\+I\+N\+AE trick, the safe implementation is automatically used for general coefficients (eg $\mathbb Z$) while the fast version is used for finite coefficients, when a certain member {\ttfamily order} exists in the coefficients (eg $\mathbb F_p$).\hypertarget{algo_cob}{}\section{Change of Basis}\label{algo_cob}
If we have bases for modules $A,B$ then $A\otimes B$ can be canonically given two lexicographical bases, that we call left and right convenient bases. But if $A,B$ are the bottom levels of free \hyperlink{namespaceMackey}{Mackey} functors then they have equivariant bases and the tensor product also gets an equivariant basis, called the canonical one. The left and right convenient bases are used to write the left and right differentials in a simple manner (hence their designation as convenient). The canonical bases are used to transfer. To get the change of basis matrix, we are reduced to computing the permutation $a^{-1}b$ where $a,b$ are two permutations of the same set.\hypertarget{algo_box}{}\section{Box product}\label{algo_box}
Computing the tensor product of Chain complexes breaks down to computing the left and right differentials $L(x\otimes y)=dx\otimes y$ and $R(x\otimes y)=(-1)^{|x|}x\otimes dy$ respectively. If we use the convenient bases explained in the previous section, these are just block diagonal matrices with the blocks being the differential from the original chains $d$. To get $L,R$ w.\+r.\+t. the canonical bases, we need to apply the change of basis matrices. Once we do that the total differential of the tensor product is just $L+R$. To be more accurate, $L$ is not a single differential, but rather a sequence of them, one for each summand of the Box product; $(C\otimes D)_n\to (C\otimes D)_{n-1}$ is a map $C_n\otimes D_0\oplus\cdots \oplus C_0\otimes D_n\to C_0\otimes D_{n-1}\oplus\cdots\oplus C_{n-1}\otimes D_0$. Each summand of this map is computed separately into an $L$ and an $R$, and then these are mixed together to form the total differential. The mixing specifies that we start with a block $ L_0$, then place $ R_0$ directly below it, then $L_1$ adjecent to the right of $ R_0$ etc.\hypertarget{algo_graph}{}\section{Graphs}\label{algo_graph}

\begin{DoxyItemize}
\item For weighted graphs we want the shortest path from a given source to all other points. I use a straightforward implementation of Dikjstra\textquotesingle{}s algorithm using std\+::priority\+\_\+queue.
\item For graphs of two colors, we are interested in the paths from the source to all points with the minimum numer of alternating colors (an alternation of colors means switching from division to multiplication and vice-\/versa). This problem can be easily reduced to finding the shortest path for weighted graphs, by using a sort of \char`\"{}dual\char`\"{} graph where now the nodes are colored and the now monochrome edges between same colored nodes have weight 0, while for different colored nodes we get weight 1. To get the new graph simply duplicate the nodes of the original, color the originals by red and the new ones by blue, and quadruple the edges (so we using all combinations of colored nodes) and set the weights as I just explained. After that, find the red and blue paths starting from a red/blue source and ending to each point, compare them in length and choose the shortest one. 
\end{DoxyItemize}